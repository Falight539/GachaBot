{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 14:21:20.494005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 14:21:22.377057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'Dataset.csv')\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "# Setting date column to index\n",
    "# dataset = dataset.set_index(['Date'], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(dataset.columns[[2, 3, 4, 5, 6]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sort_values(by=[\"Date\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-10-02 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>2018-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>2018-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2018-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>2018-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>2018-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date\n",
       "1278 2018-10-02\n",
       "1277 2018-10-03\n",
       "1276 2018-10-04\n",
       "1275 2018-10-05\n",
       "1274 2018-10-08\n",
       "...         ...\n",
       "4    2023-09-27\n",
       "3    2023-09-28\n",
       "2    2023-09-29\n",
       "1    2023-10-01\n",
       "0    2023-10-02\n",
       "\n",
       "[1279 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dataset.drop([\"Price\"], axis=1)\n",
    "print(temp.shape)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "x = StandardScaler().fit_transform(dataset.drop([\"Price\"], axis=1))\n",
    "y = dataset['Price'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Dense\n",
    "from keras.models import Sequential, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 14:21:43.858362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 14:21:44.011940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:44.012076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:44.015819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:44.015899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:44.015932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:46.053991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:46.054686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:46.054735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-03 14:21:46.054920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-03 14:21:46.055115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5927 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 7)                 210       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218 (872.00 Byte)\n",
      "Trainable params: 218 (872.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(7, input_shape=(x_train.shape[1], 1), activation='linear', kernel_initializer='lecun_uniform', return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.metrics.mean_squared_error,\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1151/1151 [==============================] - 5s 3ms/step - loss: 391.0580 - rmse: 19.7752\n",
      "Epoch 2/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 8.4729 - rmse: 2.9108\n",
      "Epoch 3/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 3.3602 - rmse: 1.8331\n",
      "Epoch 4/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 2.7609 - rmse: 1.6616\n",
      "Epoch 5/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 2.6139 - rmse: 1.6167\n",
      "Epoch 6/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 1.9082 - rmse: 1.3814\n",
      "Epoch 7/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 1.4110 - rmse: 1.1879\n",
      "Epoch 8/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 1.1291 - rmse: 1.0626\n",
      "Epoch 9/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.9734 - rmse: 0.9866\n",
      "Epoch 10/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.8850 - rmse: 0.9407\n",
      "Epoch 11/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.8329 - rmse: 0.9126\n",
      "Epoch 12/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.8017 - rmse: 0.8954\n",
      "Epoch 13/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7830 - rmse: 0.8849\n",
      "Epoch 14/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7721 - rmse: 0.8787\n",
      "Epoch 15/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7660 - rmse: 0.8752\n",
      "Epoch 16/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7627 - rmse: 0.8733\n",
      "Epoch 17/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7609 - rmse: 0.8723\n",
      "Epoch 18/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7598 - rmse: 0.8717\n",
      "Epoch 19/100\n",
      "1151/1151 [==============================] - 1s 1ms/step - loss: 0.7590 - rmse: 0.8712\n",
      "Epoch 20/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7583 - rmse: 0.8708\n",
      "Epoch 21/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7574 - rmse: 0.8703\n",
      "Epoch 22/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7564 - rmse: 0.8697\n",
      "Epoch 23/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7553 - rmse: 0.8691\n",
      "Epoch 24/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7541 - rmse: 0.8684\n",
      "Epoch 25/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7529 - rmse: 0.8677\n",
      "Epoch 26/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7519 - rmse: 0.8671\n",
      "Epoch 27/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7511 - rmse: 0.8667\n",
      "Epoch 28/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7506 - rmse: 0.8664\n",
      "Epoch 29/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7503 - rmse: 0.8662\n",
      "Epoch 30/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7502 - rmse: 0.8662\n",
      "Epoch 31/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7504 - rmse: 0.8663\n",
      "Epoch 32/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7507 - rmse: 0.8664\n",
      "Epoch 33/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7512 - rmse: 0.8667\n",
      "Epoch 34/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7517 - rmse: 0.8670\n",
      "Epoch 35/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7522 - rmse: 0.8673\n",
      "Epoch 36/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7528 - rmse: 0.8676\n",
      "Epoch 37/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7534 - rmse: 0.8680\n",
      "Epoch 38/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7539 - rmse: 0.8683\n",
      "Epoch 39/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7544 - rmse: 0.8686\n",
      "Epoch 40/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7549 - rmse: 0.8689\n",
      "Epoch 41/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7553 - rmse: 0.8691\n",
      "Epoch 42/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7557 - rmse: 0.8693\n",
      "Epoch 43/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7560 - rmse: 0.8695\n",
      "Epoch 44/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7563 - rmse: 0.8697\n",
      "Epoch 45/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7565 - rmse: 0.8698\n",
      "Epoch 46/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7567 - rmse: 0.8699\n",
      "Epoch 47/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7568 - rmse: 0.8699\n",
      "Epoch 48/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7568 - rmse: 0.8700\n",
      "Epoch 49/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7568 - rmse: 0.8700\n",
      "Epoch 50/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7567 - rmse: 0.8699\n",
      "Epoch 51/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7566 - rmse: 0.8698\n",
      "Epoch 52/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7564 - rmse: 0.8697\n",
      "Epoch 53/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7562 - rmse: 0.8696\n",
      "Epoch 54/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7559 - rmse: 0.8694\n",
      "Epoch 55/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7555 - rmse: 0.8692\n",
      "Epoch 56/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7551 - rmse: 0.8690\n",
      "Epoch 57/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7546 - rmse: 0.8687\n",
      "Epoch 58/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7541 - rmse: 0.8684\n",
      "Epoch 59/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7535 - rmse: 0.8681\n",
      "Epoch 60/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7529 - rmse: 0.8677\n",
      "Epoch 61/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7523 - rmse: 0.8673\n",
      "Epoch 62/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7516 - rmse: 0.8670\n",
      "Epoch 63/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7509 - rmse: 0.8666\n",
      "Epoch 64/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7502 - rmse: 0.8661\n",
      "Epoch 65/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7494 - rmse: 0.8657\n",
      "Epoch 66/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7487 - rmse: 0.8653\n",
      "Epoch 67/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7479 - rmse: 0.8648\n",
      "Epoch 68/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7471 - rmse: 0.8644\n",
      "Epoch 69/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7463 - rmse: 0.8639\n",
      "Epoch 70/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7455 - rmse: 0.8635\n",
      "Epoch 71/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7448 - rmse: 0.8630\n",
      "Epoch 72/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7440 - rmse: 0.8625\n",
      "Epoch 73/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7432 - rmse: 0.8621\n",
      "Epoch 74/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7424 - rmse: 0.8616\n",
      "Epoch 75/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7416 - rmse: 0.8611\n",
      "Epoch 76/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7408 - rmse: 0.8607\n",
      "Epoch 77/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7400 - rmse: 0.8602\n",
      "Epoch 78/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7392 - rmse: 0.8597\n",
      "Epoch 79/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7383 - rmse: 0.8593\n",
      "Epoch 80/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7375 - rmse: 0.8588\n",
      "Epoch 81/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7367 - rmse: 0.8583\n",
      "Epoch 82/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7358 - rmse: 0.8578\n",
      "Epoch 83/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7350 - rmse: 0.8573\n",
      "Epoch 84/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7341 - rmse: 0.8568\n",
      "Epoch 85/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7332 - rmse: 0.8563\n",
      "Epoch 86/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7323 - rmse: 0.8558\n",
      "Epoch 87/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7314 - rmse: 0.8552\n",
      "Epoch 88/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7305 - rmse: 0.8547\n",
      "Epoch 89/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7295 - rmse: 0.8541\n",
      "Epoch 90/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7286 - rmse: 0.8536\n",
      "Epoch 91/100\n",
      "1151/1151 [==============================] - 4s 3ms/step - loss: 0.7276 - rmse: 0.8530\n",
      "Epoch 92/100\n",
      "1151/1151 [==============================] - 3s 3ms/step - loss: 0.7265 - rmse: 0.8524\n",
      "Epoch 93/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7255 - rmse: 0.8518\n",
      "Epoch 94/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7245 - rmse: 0.8512\n",
      "Epoch 95/100\n",
      "1151/1151 [==============================] - 1s 1ms/step - loss: 0.7234 - rmse: 0.8505\n",
      "Epoch 96/100\n",
      "1151/1151 [==============================] - 2s 2ms/step - loss: 0.7223 - rmse: 0.8499\n",
      "Epoch 97/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7212 - rmse: 0.8493\n",
      "Epoch 98/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7201 - rmse: 0.8486\n",
      "Epoch 99/100\n",
      "1151/1151 [==============================] - 2s 1ms/step - loss: 0.7190 - rmse: 0.8479\n",
      "Epoch 100/100\n",
      "1151/1151 [==============================] - 1s 1ms/step - loss: 0.7178 - rmse: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0b46f8dee0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train[:, :, np.newaxis], y_train, epochs=100, batch_size=1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.958412]\n",
      " [36.975574]\n",
      " [36.981228]\n",
      " [36.98685 ]\n",
      " [36.992447]\n",
      " [36.99801 ]\n",
      " [37.01451 ]\n",
      " [37.019955]\n",
      " [37.025364]\n",
      " [37.03075 ]\n",
      " [37.036102]\n",
      " [37.051983]\n",
      " [37.057224]\n",
      " [37.06243 ]\n",
      " [37.067608]\n",
      " [37.072765]\n",
      " [37.088062]\n",
      " [37.0931  ]\n",
      " [37.09812 ]\n",
      " [37.103107]\n",
      " [37.108067]\n",
      " [37.122803]\n",
      " [37.12766 ]\n",
      " [37.132492]\n",
      " [37.137302]\n",
      " [37.142082]\n",
      " [37.156277]\n",
      " [37.16096 ]\n",
      " [37.165623]\n",
      " [37.170254]\n",
      " [37.174866]\n",
      " [37.188553]\n",
      " [37.19307 ]\n",
      " [37.197567]\n",
      " [37.20203 ]\n",
      " [37.20648 ]\n",
      " [37.21968 ]\n",
      " [37.224037]\n",
      " [37.22837 ]\n",
      " [37.23269 ]\n",
      " [37.236977]\n",
      " [37.24972 ]\n",
      " [37.253933]\n",
      " [37.258118]\n",
      " [37.26228 ]\n",
      " [37.266426]\n",
      " [37.278732]\n",
      " [37.282806]\n",
      " [37.286842]\n",
      " [37.290863]\n",
      " [37.29487 ]\n",
      " [37.306767]\n",
      " [37.310696]\n",
      " [37.314606]\n",
      " [37.318497]\n",
      " [37.322365]\n",
      " [37.333874]\n",
      " [37.33767 ]\n",
      " [37.34145 ]\n",
      " [37.34521 ]\n",
      " [37.348957]\n",
      " [37.360092]\n",
      " [37.363766]\n",
      " [37.36743 ]\n",
      " [37.371067]\n",
      " [37.374695]\n",
      " [37.385475]\n",
      " [37.389038]\n",
      " [37.392586]\n",
      " [37.39611 ]\n",
      " [37.39962 ]\n",
      " [37.41007 ]\n",
      " [37.413525]\n",
      " [37.416958]\n",
      " [37.420376]\n",
      " [37.42378 ]\n",
      " [37.433914]\n",
      " [37.43726 ]\n",
      " [37.440594]\n",
      " [37.44391 ]\n",
      " [37.447212]\n",
      " [37.457043]\n",
      " [37.46029 ]\n",
      " [37.463524]\n",
      " [37.466747]\n",
      " [37.469955]\n",
      " [37.4795  ]\n",
      " [37.48266 ]\n",
      " [37.4858  ]\n",
      " [37.488934]\n",
      " [37.492046]\n",
      " [37.501324]\n",
      " [37.50439 ]\n",
      " [37.507446]\n",
      " [37.51049 ]\n",
      " [37.513523]\n",
      " [37.522545]\n",
      " [37.525528]\n",
      " [37.5285  ]\n",
      " [37.53146 ]\n",
      " [37.534412]\n",
      " [37.543194]\n",
      " [37.5461  ]\n",
      " [37.548992]\n",
      " [37.551876]\n",
      " [37.554752]\n",
      " [37.563305]\n",
      " [37.566135]\n",
      " [37.56896 ]\n",
      " [37.571766]\n",
      " [37.574566]\n",
      " [37.582912]\n",
      " [37.58567 ]\n",
      " [37.588425]\n",
      " [37.591164]\n",
      " [37.5939  ]\n",
      " [37.602036]\n",
      " [37.604725]\n",
      " [37.607414]\n",
      " [37.61009 ]\n",
      " [37.612755]\n",
      " [37.62071 ]\n",
      " [37.62334 ]\n",
      " [37.62596 ]\n",
      " [37.628567]\n",
      " [37.631176]\n",
      " [37.636368]\n",
      " [37.63895 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flight/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2023-10-3'\n",
    "end = '2023-10-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, start: str, end: str):\n",
    "\n",
    "    data = {\"Date\": []}\n",
    "\n",
    "    start_y, start_m, start_d = start.split('-')\n",
    "    end_y, end_m, end_d = end.split('-')\n",
    "\n",
    "    date = datetime(int(start_y), int(start_m), int(start_d), 0, 0, 0)\n",
    "    stop = datetime(int(end_y), int(end_m), int(end_d), 0, 0, 0)\n",
    "\n",
    "    for i in range(30):\n",
    "        data['Date'].append(pd.Timestamp(date))\n",
    "        if date == stop:\n",
    "            break\n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    x_new = pd.DataFrame(data)\n",
    "\n",
    "    return x_new\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "new_model = load_model(r'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "x_new = StandardScaler().fit_transform(forecast(1, start, end))\n",
    "pred = new_model.predict(x_new[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "37.535374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.898527],\n",
       "       [26.451122],\n",
       "       [26.180662],\n",
       "       [26.145796],\n",
       "       [26.373257],\n",
       "       [26.795553],\n",
       "       [27.231945],\n",
       "       [27.477673],\n",
       "       [27.426933],\n",
       "       [27.115517],\n",
       "       [26.702883],\n",
       "       [26.468082],\n",
       "       [26.806974],\n",
       "       [28.083475],\n",
       "       [30.239798],\n",
       "       [32.63644 ],\n",
       "       [34.600792],\n",
       "       [35.923   ],\n",
       "       [36.732006],\n",
       "       [37.22156 ],\n",
       "       [37.535374]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(pred[20][0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.535374], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
